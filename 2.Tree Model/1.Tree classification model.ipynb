{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算原始数据集的信息熵\n",
    "from math import *\n",
    "def cal_shannonent(data):\n",
    "    data_size=len(data)    #计算数据集大小\n",
    "    label_count={}         #初始化label，number字典\n",
    "    for i in data:         #迭代每一条数据，并记录每个label出现的次数\n",
    "        label=i[-1]\n",
    "        if label not in label_count.keys():\n",
    "            label_count[label]=1\n",
    "        else:\n",
    "            label_count[label]+=1\n",
    "    shannonent=0            #初始化信息熵\n",
    "    for label in label_count.keys():      #迭代计算信息熵\n",
    "        prob=label_count[label]/data_size\n",
    "        shannonent-=prob*log(prob,2)\n",
    "    return shannonent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据字段(axis)和字段中的value进行切分数据集\n",
    "def split_data(data,axis,value):\n",
    "    '''将原始数据集中特征索引位为axis且值为value的数据抽取出来'''\n",
    "    new_data=[]\n",
    "    for i in data:\n",
    "        if i[axis]==value:\n",
    "            new_i=i[:axis]\n",
    "            new_i.extend(i[axis+1:])\n",
    "            new_data.append(new_i)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选取当前数据集最优的特征，（获得最大信息增益的特征）\n",
    "def get_bestfeature(data):\n",
    "    n_features=len(data[0])-1  #最后一列为target字段\n",
    "    base_shannonent=cal_shannonent(data)  #计算元数据集目标target信息熵\n",
    "    best_feature=-1\n",
    "    best_inf_gain=0.000   #初始化信息熵，最优特征\n",
    "    for feature_index in range(n_features):    #迭代特征，进行特征选取\n",
    "        value_set=set([i[feature_index] for i in data])\n",
    "        new_shannonent=0        \n",
    "        for value in value_set:\n",
    "            splited_data=split_data(data,feature_index,value)\n",
    "            prob=len(splited_data)/float(len(data))\n",
    "            new_shannonent+=prob*cal_shannonent(splited_data)\n",
    "        inf_gain=base_shannonent-new_shannonent\n",
    "        if inf_gain>best_inf_gain:\n",
    "            best_inf_gain=inf_gain\n",
    "            best_feature=feature_index\n",
    "\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据列表中的value，获得计数最多的value\n",
    "import operator\n",
    "def majority_vote(class_list):\n",
    "    value_set=set(class_list)\n",
    "    class_counts={}     #value,count\n",
    "    for i in class_list:\n",
    "        if i not in class_counts.keys():\n",
    "            class_counts[i]=0\n",
    "        class_counts[i]+=1\n",
    "    majority=sorted(class_counts.items(),key=operator.itemgetter(1),reverse=True)[0][0]\n",
    "    return majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(data,feature_labels):  \n",
    "    '''输入data和数据的特征label来构建决策树'''\n",
    "    feature_labels=feature_labels[:]   #feature_lables是一个列表，此行代码是为了防止此函数在全局修改feature_label变量\n",
    "    class_list=[i[-1] for i in data]  #获取当前数据集的类别列表\n",
    "    if class_list.count(class_list[0])==len(class_list):  #如果数据集的当前类别等于数据集的行数，直接返回此类别\n",
    "        return class_list[0]        \n",
    "    if len(data[0])==1:           #如果此数据只剩下类别特征，返回占比最多的类别\n",
    "        return majority_vote(class_list)\n",
    "    \n",
    "    best_feature_index=get_bestfeature(data)      #计算当前数据集最优切分特征的index\n",
    "    best_feature_label=feature_labels[best_feature_index]    #获取当前数据最优切分特征的label\n",
    "    tree={best_feature_label:{}}           \n",
    "    del (feature_labels[best_feature_index])      #在feature_labes中删除此特征\n",
    "    \n",
    "    best_feature_values=[i[best_feature_index] for i in data]     #获取此特征不同的value集合 \n",
    "    unique_values=set(best_feature_values)\n",
    "    for value in unique_values:       #遍历此特征的value迭代的构建树\n",
    "        sub_labels=feature_labels[:]\n",
    "        tree[best_feature_label][value]=create_tree(split_data(data,\n",
    "                                                               best_feature_index,value),sub_labels)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree_model,feature_labels,test_vector):\n",
    "    first_str=list(tree_model.keys())[0]\n",
    "    second_dict=tree_model[first_str]\n",
    "    feature_index=feature_labels.index(first_str)\n",
    "    for key in second_dict.keys():\n",
    "        if test_vector[feature_index]== key:\n",
    "            if isinstance(second_dict[key],dict):\n",
    "                class_lable=classify(second_dict[key],feature_labels,test_vector)\n",
    "            else:\n",
    "                class_lable=second_dict[key]\n",
    "    return class_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904030710172744\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('DecisionTree.csv')\n",
    "train_data=data.sample(frac=0.8)\n",
    "test_data=train_data.sample(frac=0.12)\n",
    "tree=create_tree(train_data.values.tolist(),train_data.columns.tolist())\n",
    "income_data=test_data.values.tolist()\n",
    "correct_count=0\n",
    "for i in income_data:\n",
    "    if classify(tree,test_data.columns.tolist(),i)==i[-1]:\n",
    "        correct_count=correct_count+1\n",
    "print(correct_count/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('DecisionTree.csv')\n",
    "train_data=data.sample(frac=0.8)\n",
    "test_data=train_data.sample(frac=0.12)\n",
    "train_data=pd.get_dummies(train_data)\n",
    "test_data=pd.get_dummies(test_data)\n",
    "tree=create_tree(train_data.values.tolist(),train_data.columns.tolist())\n",
    "income_data=test_data.values.tolist()\n",
    "correct_count=0\n",
    "for i in income_data:\n",
    "    if classify(tree,test_data.columns.tolist(),i)==i[-1]:\n",
    "        correct_count=correct_count+1\n",
    "print(correct_count/len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
