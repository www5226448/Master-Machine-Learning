{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Feb 4, 2011\n",
    "Tree-Based Regression Methods\n",
    "@author: Peter Harrington\n",
    "@eitor:Jude.wang\n",
    "'''\n",
    "from numpy import *\n",
    "\n",
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    dataMat = []                #assume last column is target value\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = map(float,curLine) \n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat\n",
    "\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    \"\"\"对数据集中的某一特征根据value切分成两个数据集\"\"\"\n",
    "    mat0 = dataSet[nonzero(dataSet[:,feature] > value)[0],:]\n",
    "    mat1 = dataSet[nonzero(dataSet[:,feature] <= value)[0],:]\n",
    "    return mat0,mat1\n",
    "\n",
    "def regLeaf(dataSet):\n",
    "    '''返回数据集的叶子节点【叶子节点即为当前叶子节点样本中的均值】'''\n",
    "    #returns the value used for each leaf\n",
    "    return mean(dataSet[:,-1])\n",
    "\n",
    "def regErr(dataSet):\n",
    "    \"\"\"返回数据集最后一切的方差*此数据集的样本数\"\"\"\n",
    "    return var(dataSet[:,-1]) * shape(dataSet)[0]\n",
    "\n",
    "def chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    '''返回数据集，连续特征的最优可切分的feature_index和切分的value'''\n",
    "    tolS = ops[0]   #容许的误差下降值\n",
    "    tolN = ops[1]   #切分的最少样本数\n",
    "    \n",
    "    #if all the target variables are the same value: quit and return value\n",
    "    if len(set(dataSet[:,-1].T.tolist())) == 1: #exit cond 1\n",
    "        return None, leafType(dataSet)\n",
    "    \n",
    "    m,n = shape(dataSet)\n",
    "    #the choice of the best feature is driven by Reduction in RSS error from mean\n",
    "    S = errType(dataSet)  #当前数据集未切分之前的RSS\n",
    "    bestS = inf   #最大方差\n",
    "    bestIndex = 0   #初始化最优索引特征\n",
    "    bestValue = 0   #初始化最有特征的最优切分值\n",
    "    \n",
    "    for featIndex in range(n-1):  #遍历特征\n",
    "        for splitVal in set(dataSet[:,featIndex]):     #遍历当前特征的可切分的unique_values\n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            if (shape(mat0)[0] < tolN) or (shape(mat1)[0] < tolN):  \n",
    "                continue   #如果当前特征，切分值不满于预先设定的切分门槛，跳出当前循环，继续执行下一循环\n",
    "            newS = errType(mat0) + errType(mat1)   #满足预先设定的切分门槛,返回切分后的SSR之和  \n",
    "            if newS < bestS:    #如果此次切分后的SSR小于之前未切分的SSR，更新最优切分\n",
    "                bestIndex = featIndex   \n",
    "                bestValue = splitVal\n",
    "                bestS = newS            \n",
    "    if (S - bestS) < tolS:     #if the decrease (S-bestS) is less than a threshold don't do the split\n",
    "        return None, leafType(dataSet) \n",
    "    \n",
    "    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    \n",
    "    if (shape(mat0)[0] < tolN) or (shape(mat1)[0] < tolN):  #如果切分后的样本数量小于约定的返回None\n",
    "        return None, leafType(dataSet)\n",
    "    return bestIndex,bestValue    #returns the best feature to split onand the value used for that split\n",
    "              \n",
    "\n",
    "def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    #assume dataSet is NumPy Mat so we can array filtering\n",
    "    feat, val = chooseBestSplit(dataSet, leafType, errType, ops)   #choose the best split\n",
    "    if feat == None: \n",
    "        return val #如果还有可切分的特征，直接返回叶子节点的均值\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, leafType, errType, ops)  #left,value>split_value\n",
    "    retTree['right'] = createTree(rSet, leafType, errType, ops)  #right,value<=split_value\n",
    "    return retTree  \n",
    "\n",
    "def isTree(obj):\n",
    "    '''用于判断当前处理的节点是否为叶子节点'''\n",
    "    return isinstance(obj,dict)\n",
    "\n",
    "def getMean(tree):\n",
    "    '''递归函数，从上往下遍历树直到叶子节点位置，如果找到两个叶子节点，就计算平均值'''\n",
    "    if isTree(tree['right']): \n",
    "        tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): \n",
    "        tree['left'] = getMean(tree['left'])\n",
    "    return (tree['left']+tree['right'])/2.0\n",
    "    \n",
    "def prune(tree, testData):\n",
    "    \"\"\"使用测试集对模型进行后剪枝\"\"\"\n",
    "    if shape(testData)[0] == 0: #如果测试集已经没有了数据，模型不再分割 直接返回剩余的均值\n",
    "        return getMean(tree)        \n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):#如果左右分支其中有一个是树,进行分割\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])        \n",
    "    if isTree(tree['left']):        #如果左分支为树，对左分支进行后剪枝\n",
    "        tree['left'] = prune(tree['left'], lSet)       \n",
    "    if isTree(tree['right']):     #如果右分支为树，对右分支进行分割\n",
    "        tree['right'] =  prune(tree['right'], rSet)       \n",
    "    if not isTree(tree['left']) and not isTree(tree['right']): #如果左右分支都为叶子节点，尝试合并        \n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal']) #按照左右分支进行拆分数据集     \n",
    "        errorNoMerge = sum(power(lSet[:,-1] - tree['left'],2))+sum(power(rSet[:,-1] - tree['right'],2))    #计算没有合并的SSR      \n",
    "        treeMean = (tree['left']+tree['right'])/2.0      #计算合并后的左右叶子的值       \n",
    "        errorMerge = sum(power(testData[:,-1] - treeMean,2))  #计算合并后的SSR    \n",
    "        if errorMerge < errorNoMerge:   #判断是否满足合并条件\n",
    "            print (\"merging\")\n",
    "            return treeMean\n",
    "        else: \n",
    "            return tree\n",
    "    else: \n",
    "        return tree\n",
    "        \n",
    "def linearSolve(dataSet):   #helper function used in two places\n",
    "    m,n = shape(dataSet)\n",
    "    X = ones((m,n))\n",
    "    Y = ones((m,1))    #create a copy of data with 1 in 0th postion，偏置项b\n",
    "    X[:,1:n] = dataSet[:,0:n-1]\n",
    "    Y = dataSet[:,-1]    #and strip out Y\n",
    "    xTx=linalg.inv(dot(X.T,X))\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        raise NameError('This matrix is singular, cannot do inverse,\\n\\\n",
    "        try increasing the second value of ops')\n",
    "    ws = dot(xTx ,dot(X.T , Y))\n",
    "    return mat(ws),mat(X),mat(Y)\n",
    "\n",
    "def modelLeaf(dataSet):#create linear model and return coeficients\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    return ws\n",
    "\n",
    "def modelErr(dataSet):\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    yHat = X * ws.T\n",
    "    return sum(power(Y - yHat,2))\n",
    "    \n",
    "def regTreeEval(model, inDat):\n",
    "    return model.astype(float)\n",
    "\n",
    "def modelTreeEval(model, inDat): \n",
    "    model=array(model).flatten()\n",
    "    inDat=array(inDat).flatten()\n",
    "    intercept=model[0]\n",
    "    coef=model[1:]\n",
    "    value=coef.dot(inDat.T)+intercept\n",
    "    return value\n",
    "\n",
    "def treeForeCast(tree, inData, modelEval=regTreeEval):\n",
    "    if not isTree(tree):              #如果不为树，返回结果\n",
    "        return modelEval(tree, inData) \n",
    "    if inData[tree['spInd']] > tree['spVal']:    #如果大于，走左分支\n",
    "        if isTree(tree['left']):                 #如果左分支为树，递归继续调用此方法\n",
    "            return treeForeCast(tree['left'], inData, modelEval)    \n",
    "        else:                  #如果左分支已经不为树，返回此节点的值\n",
    "            return modelEval(tree['left'], inData)\n",
    "    else:              #如果小于等于，走又分支\n",
    "        if isTree(tree['right']):     #如果为树，持续调用\n",
    "            return treeForeCast(tree['right'], inData, modelEval)\n",
    "        else:                     #如果为叶子节点，返回模型数据\n",
    "            return modelEval(tree['right'], inData)\n",
    "        \n",
    "def createForeCast(tree, testData, modelEval=regTreeEval):\n",
    "    m=len(testData)\n",
    "    yHat = zeros(m)\n",
    "    for i in range(m):\n",
    "        yHat[i] = treeForeCast(tree, testData[i], modelEval)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8465.595505617977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X,y=load_diabetes().data,load_diabetes().target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "sklearn_regressiontree=DecisionTreeRegressor().fit(X_train,y_train)\n",
    "pre=sklearn_regressiontree.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3806.17808988764"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "sklearn_randomForest=RandomForestRegressor().fit(X_train,y_train)\n",
    "pre=sklearn_randomForest.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用自写的CARD算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4521.980824231781"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=concatenate([X_train,y_train.reshape(-1,1)],axis=1)\n",
    "self_tree=createTree(train_data,leafType=modelLeaf,errType=modelErr,ops=(2,20))\n",
    "treeForeCast(self_tree,X_test[1],modelEval=modelTreeEval)\n",
    "pre=createForeCast(self_tree,X_test,modelEval=modelTreeEval)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用自写的回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging\n",
      "merging\n",
      "merging\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4000.924117187969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tree=createTree(train_data,ops=(2,20))\n",
    "pure_data=concatenate([X_test,y_test.reshape(-1,1)],axis=1)\n",
    "self_tree=prune(self_tree,pure_data)\n",
    "pre=createForeCast(self_tree,X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.使用简单线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193.451536179984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "sklearn_LR=LinearRegression().fit(X_train,y_train)\n",
    "res_LR=sklearn_LR.predict(X_test)\n",
    "mean_squared_error(res_LR,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6040.194058456038"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "sklearn_SVR=SVR().fit(X_train,y_train)\n",
    "pre=sklearn_SVR.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
