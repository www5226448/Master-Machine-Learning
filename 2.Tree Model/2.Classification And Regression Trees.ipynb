{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Feb 4, 2011\n",
    "Tree-Based Regression Methods\n",
    "@author: Peter Harrington\n",
    "@eitor:Jude.wang\n",
    "'''\n",
    "from numpy import *\n",
    "\n",
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    dataMat = []                #assume last column is target value\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = map(float,curLine) \n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat\n",
    "\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    \"\"\"对数据集中的某一特征根据value切分成两个数据集\"\"\"\n",
    "    mat0 = dataSet[nonzero(dataSet[:,feature] > value)[0],:]\n",
    "    mat1 = dataSet[nonzero(dataSet[:,feature] <= value)[0],:]\n",
    "    return mat0,mat1\n",
    "\n",
    "def regLeaf(dataSet):\n",
    "    '''返回数据集的叶子节点【叶子节点即为当前叶子节点样本中的均值】'''\n",
    "    #returns the value used for each leaf\n",
    "    return mean(dataSet[:,-1])\n",
    "\n",
    "def regErr(dataSet):\n",
    "    \"\"\"返回数据集最后一切的方差*此数据集的样本数\"\"\"\n",
    "    return var(dataSet[:,-1]) * shape(dataSet)[0]\n",
    "\n",
    "def chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    '''返回数据集，连续特征的最优可切分的feature_index和切分的value'''\n",
    "    tolS = ops[0]   #容许的误差下降值\n",
    "    tolN = ops[1]   #切分的最少样本数\n",
    "    \n",
    "    #if all the target variables are the same value: quit and return value\n",
    "    if len(set(dataSet[:,-1].T.tolist())) == 1: #exit cond 1\n",
    "        return None, leafType(dataSet)\n",
    "    \n",
    "    m,n = shape(dataSet)\n",
    "    #the choice of the best feature is driven by Reduction in RSS error from mean\n",
    "    S = errType(dataSet)  #当前数据集未切分之前的RSS\n",
    "    bestS = inf   #最大方差\n",
    "    bestIndex = 0   #初始化最优索引特征\n",
    "    bestValue = 0   #初始化最有特征的最优切分值\n",
    "    \n",
    "    for featIndex in range(n-1):  #遍历特征\n",
    "        for splitVal in set(dataSet[:,featIndex]):     #遍历当前特征的可切分的unique_values\n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            if (shape(mat0)[0] < tolN) or (shape(mat1)[0] < tolN):  \n",
    "                continue   #如果当前特征，切分值不满于预先设定的切分门槛，跳出当前循环，继续执行下一循环\n",
    "            newS = errType(mat0) + errType(mat1)   #满足预先设定的切分门槛,返回切分后的SSR之和  \n",
    "            if newS < bestS:    #如果此次切分后的SSR小于之前未切分的SSR，更新最优切分\n",
    "                bestIndex = featIndex   \n",
    "                bestValue = splitVal\n",
    "                bestS = newS            \n",
    "    if (S - bestS) < tolS:     #if the decrease (S-bestS) is less than a threshold don't do the split\n",
    "        return None, leafType(dataSet) \n",
    "    \n",
    "    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    \n",
    "    if (shape(mat0)[0] < tolN) or (shape(mat1)[0] < tolN):  #如果切分后的样本数量小于约定的返回None\n",
    "        return None, leafType(dataSet)\n",
    "    return bestIndex,bestValue    #returns the best feature to split onand the value used for that split\n",
    "              \n",
    "\n",
    "def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    #assume dataSet is NumPy Mat so we can array filtering\n",
    "    feat, val = chooseBestSplit(dataSet, leafType, errType, ops)   #choose the best split\n",
    "    if feat == None: \n",
    "        return val #如果还有可切分的特征，直接返回叶子节点的均值\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, leafType, errType, ops)  #left,value>split_value\n",
    "    retTree['right'] = createTree(rSet, leafType, errType, ops)  #right,value<=split_value\n",
    "    return retTree  \n",
    "\n",
    "def isTree(obj):\n",
    "    '''用于判断当前处理的节点是否为叶子节点'''\n",
    "    return isinstance(obj,dict)\n",
    "\n",
    "def getMean(tree):\n",
    "    '''递归函数，从上往下遍历树直到叶子节点位置，如果找到两个叶子节点，就计算平均值'''\n",
    "    if isTree(tree['right']): \n",
    "        tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): \n",
    "        tree['left'] = getMean(tree['left'])\n",
    "    return (tree['left']+tree['right'])/2.0\n",
    "    \n",
    "def prune(tree, testData):\n",
    "    \"\"\"使用测试集对模型进行后剪枝\"\"\"\n",
    "    if shape(testData)[0] == 0: #如果测试集已经没有了数据，模型不再分割 直接返回剩余的均值\n",
    "        return getMean(tree)        \n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):#如果左右分支其中有一个是树,进行分割\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])        \n",
    "    if isTree(tree['left']):        #如果左分支为树，对左分支进行后剪枝\n",
    "        tree['left'] = prune(tree['left'], lSet)       \n",
    "    if isTree(tree['right']):     #如果右分支为树，对右分支进行分割\n",
    "        tree['right'] =  prune(tree['right'], rSet)       \n",
    "    if not isTree(tree['left']) and not isTree(tree['right']): #如果左右分支都为叶子节点，尝试合并        \n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal']) #按照左右分支进行拆分数据集     \n",
    "        errorNoMerge = sum(power(lSet[:,-1] - tree['left'],2))+sum(power(rSet[:,-1] - tree['right'],2))    #计算没有合并的SSR      \n",
    "        treeMean = (tree['left']+tree['right'])/2.0      #计算合并后的左右叶子的值       \n",
    "        errorMerge = sum(power(testData[:,-1] - treeMean,2))  #计算合并后的SSR    \n",
    "        if errorMerge < errorNoMerge:   #判断是否满足合并条件\n",
    "            print (\"merging\")\n",
    "            return treeMean\n",
    "        else: \n",
    "            return tree\n",
    "    else: \n",
    "        return tree\n",
    "        \n",
    "def linearSolve(dataSet):   #helper function used in two places\n",
    "    m,n = shape(dataSet)\n",
    "    X = ones((m,n))\n",
    "    Y = ones((m,1))    #create a copy of data with 1 in 0th postion，偏置项b\n",
    "    X[:,1:n] = dataSet[:,0:n-1]\n",
    "    Y = dataSet[:,-1]    #and strip out Y\n",
    "    xTx=linalg.inv(dot(X.T,X))\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        raise NameError('This matrix is singular, cannot do inverse,\\n\\\n",
    "        try increasing the second value of ops')\n",
    "    ws = dot(xTx ,dot(X.T , Y))\n",
    "    return mat(ws),mat(X),mat(Y)\n",
    "\n",
    "def modelLeaf(dataSet):#create linear model and return coeficients\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    return ws\n",
    "\n",
    "def modelErr(dataSet):\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    yHat = X * ws.T\n",
    "    return sum(power(Y - yHat,2))\n",
    "    \n",
    "def regTreeEval(model, inDat):\n",
    "    return model.astype(float)\n",
    "\n",
    "def modelTreeEval(model, inDat): \n",
    "    model=array(model).flatten()\n",
    "    inDat=array(inDat).flatten()\n",
    "    intercept=model[0]\n",
    "    coef=model[1:]\n",
    "    value=coef.dot(inDat.T)+intercept\n",
    "    return value\n",
    "\n",
    "def treeForeCast(tree, inData, modelEval=regTreeEval):\n",
    "    if not isTree(tree):              #如果不为树，返回结果\n",
    "        return modelEval(tree, inData) \n",
    "    if inData[tree['spInd']] > tree['spVal']:    #如果大于，走左分支\n",
    "        if isTree(tree['left']):                 #如果左分支为树，递归继续调用此方法\n",
    "            return treeForeCast(tree['left'], inData, modelEval)    \n",
    "        else:                  #如果左分支已经不为树，返回此节点的值\n",
    "            return modelEval(tree['left'], inData)\n",
    "    else:              #如果小于等于，走又分支\n",
    "        if isTree(tree['right']):     #如果为树，持续调用\n",
    "            return treeForeCast(tree['right'], inData, modelEval)\n",
    "        else:                     #如果为叶子节点，返回模型数据\n",
    "            return modelEval(tree['right'], inData)\n",
    "        \n",
    "def createForeCast(tree, testData, modelEval=regTreeEval):\n",
    "    m=len(testData)\n",
    "    yHat = zeros(m)\n",
    "    for i in range(m):\n",
    "        yHat[i] = treeForeCast(tree, testData[i], modelEval)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6185.83778735477"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X,y=make_regression(n_features=6,n_samples=300)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "sklearn_regressiontree=DecisionTreeRegressor().fit(X_train,y_train)\n",
    "pre=sklearn_regressiontree.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3105.0344932511844"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "sklearn_randomForest=RandomForestRegressor().fit(X_train,y_train)\n",
    "pre=sklearn_randomForest.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用自写的CARD算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3920293439025163e-25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=concatenate([X_train,y_train.reshape(-1,1)],axis=1)\n",
    "self_tree=createTree(train_data,leafType=modelLeaf,errType=modelErr,ops=(2,20))\n",
    "treeForeCast(self_tree,X_test[1],modelEval=modelTreeEval)\n",
    "pre=createForeCast(self_tree,X_test,modelEval=modelTreeEval)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用自写的回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9244.556536860908"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tree=createTree(train_data,ops=(2,20))\n",
    "pure_data=concatenate([X_test,y_test.reshape(-1,1)],axis=1)\n",
    "self_tree=prune(self_tree,pure_data)\n",
    "pre=createForeCast(self_tree,X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.使用简单线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.366218892653465e-26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "sklearn_LR=LinearRegression().fit(X_train,y_train)\n",
    "res_LR=sklearn_LR.predict(X_test)\n",
    "mean_squared_error(res_LR,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn中的SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17375.256784483907"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "sklearn_SVR=SVR().fit(X_train,y_train)\n",
    "pre=sklearn_SVR.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
