{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    \"\"\"Split the data set into two data sets based on the feature and values of the data set\"\"\"\n",
    "    mat0 = dataSet[np.nonzero(dataSet[:,feature] > value)[0],:]\n",
    "    mat1 = dataSet[np.nonzero(dataSet[:,feature] <= value)[0],:]\n",
    "    return mat0,mat1\n",
    "\n",
    "def chooseBestSplit(dataSet, ops=(1,4,10)):\n",
    "    tolS = ops[0]   #min_impurity_decrease\n",
    "    tolN = ops[1]   #min_samples_leaf \n",
    "    \n",
    "    #if all the target variables are the same value: quit and return value\n",
    "    if len(set(dataSet[:,-1].T.tolist())) == 1 or len(dataSet)<=ops[2]: #exit cond 1\n",
    "        return None, np.mean(dataSet[:,-1])\n",
    "\n",
    "    m,n = dataSet.shape\n",
    "    #the choice of the best feature is driven by Reduction in RSS error from mean\n",
    "    S = np.var(dataSet[:,-1]) * dataSet.shape[0]  \n",
    "    bestS = np.inf  \n",
    "    bestIndex = 0   \n",
    "    bestValue = 0   \n",
    "    for featIndex in range(n-1):  \n",
    "        for splitVal in set(dataSet[:,featIndex]):     \n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            if (mat0.shape[0] < tolN) or (mat1.shape[0] < tolN):  \n",
    "                continue  \n",
    "            newS = np.var(mat0[:,-1]) * mat0.shape[0] + np.var(mat1[:,-1]) * mat1.shape[0]   \n",
    "            if newS < bestS:    #if the cut ssr is less than the previously uncut ssr, the optimal segmentation is updated \n",
    "                bestIndex = featIndex   \n",
    "                bestValue = splitVal\n",
    "                bestS = newS            \n",
    "    if (S - bestS) < tolS:     #if the decrease (S-bestS) is less than a threshold don't do the split\n",
    "        return None, np.mean(dataSet[:,-1])\n",
    "    \n",
    "    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    \n",
    "    if (mat0.shape[0] < tolN) or (mat1.shape[0] < tolN):  \n",
    "        return None, np.mean(dataSet[:,-1])\n",
    "    return bestIndex,bestValue    #returns the best feature to split onand the value used for that split\n",
    "              \n",
    "\n",
    "def createTree(dataSet,  ops=(1,4)):\n",
    "    #assume dataSet is NumPy Mat so we can array filtering\n",
    "    feat, val = chooseBestSplit(dataSet, ops)   #choose the best split\n",
    "    if feat == None: \n",
    "        return val \n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet,  ops)  #left,value>split_value\n",
    "    retTree['right'] = createTree(rSet,  ops)  #right,value<=split_value\n",
    "    return retTree  \n",
    "\n",
    "def isTree(obj):\n",
    "    return isinstance(obj,dict)\n",
    "\n",
    "def getMean(tree):\n",
    "    if isTree(tree['right']): \n",
    "        tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): \n",
    "        tree['left'] = getMean(tree['left'])\n",
    "    return (tree['left']+tree['right'])/2.0\n",
    "    \n",
    "def prune(tree, testData):\n",
    "    if testData.shape[0] == 0: #If the test set already has no data, the model no longer splits and returns the mean directly \n",
    "        return getMean(tree)        \n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):#If one of the left and right branches is a tree, split it \n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])        \n",
    "    if isTree(tree['left']):        #If the left branch is a tree, after pruning the left branch \n",
    "        tree['left'] = prune(tree['left'], lSet)       \n",
    "    if isTree(tree['right']):    #If the right branch is a tree, split the right branch \n",
    "        tree['right'] =  prune(tree['right'], rSet)       \n",
    "    if not isTree(tree['left']) and not isTree(tree['right']): #If both left and right branches are leaf nodes, try merging        \n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal']) #Split the dataset according to the left and right branches    \n",
    "        errorNoMerge = sum(np.power(lSet[:,-1] - tree['left'],2))+sum(np.power(rSet[:,-1] - tree['right'],2))    #Calculate an unmerged ssr      \n",
    "        treeMean = (tree['left']+tree['right'])/2.0      #Calculate the value of the left and right leaves after the merge       \n",
    "        errorMerge = sum(np.power(testData[:,-1] - treeMean,2))  #Calculate the combined ssr \n",
    "        if errorMerge < errorNoMerge:   \n",
    "            return treeMean\n",
    "        else: \n",
    "            return tree\n",
    "    else: \n",
    "        return tree\n",
    "        \n",
    "\n",
    "    \n",
    "def regTreeEval(model, inDat):\n",
    "    return model.astype(float)\n",
    "\n",
    "def treeForeCast(tree, inData,modelEval=regTreeEval):\n",
    "    if not isTree(tree):             \n",
    "        return modelEval(tree, inData) \n",
    "    if inData[tree['spInd']] > tree['spVal']:  \n",
    "        if isTree(tree['left']):                 \n",
    "            return treeForeCast(tree['left'], inData,modelEval)    \n",
    "        else:                  #f left branch is not a tree,return the value\n",
    "            return modelEval(tree['left'], inData)\n",
    "    else:              #right path\n",
    "        if isTree(tree['right']):     #if it is a tree,growths\n",
    "            return treeForeCast(tree['right'], inData, modelEval)\n",
    "        else:                     #if it is a leaf node,return mean label value\n",
    "            return modelEval(tree['right'], inData)\n",
    "        \n",
    "def createForeCast(tree, testData, modelEval=regTreeEval):\n",
    "    m=len(testData)\n",
    "    y_pred= np.zeros(m)\n",
    "    for i in range(m):\n",
    "        y_pred[i] = treeForeCast(tree, testData[i], modelEval)\n",
    "    return y_pred\n",
    "\n",
    "class RegressionTree:\n",
    "    def __init__(self,min_impurity_decrease=1,\n",
    "                 min_samples_leaf=4,\n",
    "                 min_samples_split=10\n",
    "                ):\n",
    "        self.criterion='mse'\n",
    "        self.splitter='best'\n",
    "        self.max_depth=None\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.min_samples_leaf=min_samples_leaf\n",
    "        self.min_impurity_decrease =min_impurity_decrease \n",
    "    \n",
    "    def fit(self,X,y):     \n",
    "        train_data=np.concatenate([X,y.reshape(-1,1)],axis=-1)\n",
    "        self_tree=createTree(train_data,ops=(self.min_impurity_decrease ,self.min_samples_leaf,self.min_samples_split))\n",
    "        pure_data=np.concatenate([X_test,y_test.reshape(-1,1)],axis=1)\n",
    "        self.tree=prune(self_tree,pure_data)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return createForeCast(self.tree,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.730196078431366"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X,y=load_boston(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "sklearn_regressiontree=DecisionTreeRegressor().fit(X_train,y_train)\n",
    "pre=sklearn_regressiontree.predict(X_test)\n",
    "mean_squared_error(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.625     , 13.21142857, 38.64      , 28.725     , 24.07055556,\n",
       "       14.76666667, 26.8875    , 18.98571429, 20.18      , 22.625     ,\n",
       "       28.725     , 20.76690476, 33.85714286, 22.34      , 21.72      ,\n",
       "       19.3       , 14.76666667, 24.89375   , 22.5       , 17.55      ,\n",
       "       12.1       , 20.18      , 21.72      , 20.76690476, 20.18      ,\n",
       "       21.72      , 14.9       , 13.575     , 16.61428571, 24.07055556,\n",
       "       19.625     , 12.1       ,  9.66291667, 33.85714286, 16.61428571,\n",
       "       19.625     , 46.09583333, 20.76690476, 20.76690476, 18.06      ,\n",
       "       18.775     , 16.62857143, 33.25      , 36.35      , 13.21142857,\n",
       "       17.175     , 23.84      , 14.76666667,  9.66291667, 26.8875    ,\n",
       "       12.1       ,  9.66291667, 11.5       , 13.21142857, 21.72      ,\n",
       "       16.1       , 20.92539683, 20.76690476, 26.8875    , 16.62857143,\n",
       "       24.07055556, 24.89375   , 17.72      , 12.1       ,  9.66291667,\n",
       "       25.6       ,  9.66291667, 24.89375   , 33.11666667, 13.21142857,\n",
       "       50.        , 33.11666667, 38.64      , 24.07055556, 28.725     ,\n",
       "       21.72      , 29.64285714, 46.09583333, 46.09583333, 24.89375   ,\n",
       "       28.725     , 28.725     , 26.8875    , 33.11666667, 21.72      ,\n",
       "       19.3       , 20.7125    , 33.25      , 22.34      , 33.11666667,\n",
       "       20.92539683, 19.625     , 16.62857143, 24.07055556, 27.2       ,\n",
       "       27.2       , 25.6       , 20.18      , 21.1       , 33.25      ,\n",
       "       20.76690476, 12.1       ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree=RegressionTree()\n",
    "my_tree.fit(X_train,y_train)\n",
    "y_pred=my_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.039199961284666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
