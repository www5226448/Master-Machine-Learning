{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(20)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class RandomForest():\n",
    "    \"\"\"Random Forest classifier. Uses a collection of classification trees that\n",
    "    trains on random subsets of the data using a random subsets of the features.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_estimators: int\n",
    "        树的数量\n",
    "        The number of classification trees that are used.\n",
    "    max_features: int\n",
    "        每棵树选用数据集中的最大的特征数\n",
    "        The maximum number of features that the classification trees are allowed to\n",
    "        use.\n",
    "    min_samples_split: int\n",
    "        每棵树中最小的分割数，比如 min_samples_split = 2表示树切到还剩下两个数据集时就停止\n",
    "        The minimum number of samples needed to make a split when building a tree.\n",
    "    min_gain: float\n",
    "        每棵树切到小于min_gain后停止\n",
    "        The minimum impurity required to split the tree further.\n",
    "    max_depth: int\n",
    "        每棵树的最大层数\n",
    "        The maximum depth of a tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=100, min_samples_split=2, min_gain=0,\n",
    "                 max_depth=None, max_features=None):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "\n",
    "        self.trees = []\n",
    "        # 建立森林(bulid forest)\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeClassifier(min_samples_split=self.min_samples_split, min_impurity_decrease=self.min_gain,\n",
    "                                      max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def get_bootstrap_data(self, X, Y):\n",
    "\n",
    "        # 通过bootstrap的方式获得n_estimators组数据\n",
    "        # get int(n_estimators) datas by bootstrap\n",
    "\n",
    "        m = X.shape[0]\n",
    "        Y = Y.reshape(m, 1)\n",
    "\n",
    "        X_Y = np.hstack((X, Y))  # 合并X和Y，方便bootstrap (conbine X and Y)\n",
    "        np.random.shuffle(X_Y)  #随机打乱数据\n",
    "\n",
    "        data_sets = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idm = np.random.choice(m, m, replace=True)  #这里抽取数据允许重复\n",
    "            bootstrap_X_Y = X_Y[idm, :]\n",
    "            bootstrap_X = bootstrap_X_Y[:, :-1]\n",
    "            bootstrap_Y = bootstrap_X_Y[:, -1:]\n",
    "            data_sets.append([bootstrap_X, bootstrap_Y])\n",
    "        return data_sets\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # 训练，每棵树使用随机的数据集(bootstrap)和随机的特征\n",
    "        # every tree use random data set(bootstrap) and random feature\n",
    "        sub_sets = self.get_bootstrap_data(X, Y)\n",
    "        n_features = X.shape[1]\n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "        for i in range(self.n_estimators):\n",
    "            # 生成随机的特征\n",
    "            # get random feature\n",
    "            sub_X, sub_Y = sub_sets[i]\n",
    "            idx = np.random.choice(n_features, self.max_features, replace=True)  #获取随机特征\n",
    "            sub_X = sub_X[:, idx]\n",
    "            self.trees[i].fit(sub_X, sub_Y)\n",
    "            self.trees[i].feature_indices = idx  #获得此次训练时使用的特征，以便于预测时使用\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_preds = []\n",
    "        for i in range(self.n_estimators):\n",
    "            idx = self.trees[i].feature_indices\n",
    "            sub_X = X[:, idx]\n",
    "            y_pre = self.trees[i].predict(sub_X)\n",
    "            y_preds.append(y_pre)\n",
    "        y_preds = np.array(y_preds).T\n",
    "        y_pred = []\n",
    "        for y_p in y_preds:\n",
    "            # np.bincount()可以统计每个索引出现的次数\n",
    "            # np.argmax()可以返回数组中最大值的索引\n",
    "            # cheak np.bincount() and np.argmax() in numpy Docs\n",
    "            y_pred.append(np.bincount(y_p.astype('int')).argmax())\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X,y=make_classification()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "model=RandomForest()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre=model.predict(X_test)\n",
    "accuracy_score(y_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
