{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self,numIt=500):\n",
    "        self.numIt=numIt\n",
    "        self.fitted=None\n",
    "              \n",
    "    def fit(self,dataArray,classLabels):\n",
    "        classLabels=2*classLabels-1\n",
    "        self.estimators_,self.estimator_weights_,self.estimator_errors_=AdaBoostClassifier.adaBoostTrainDS(dataArray,\n",
    "                                                                                                           classLabels,self.numIt)\n",
    "        self.fitted=True\n",
    "        return self\n",
    "        \n",
    "    def predict(self,dataArray):\n",
    "        if self.fitted is None:\n",
    "            raise Exception('The model has not yet been trained.')\n",
    "        return (AdaBoostClassifier.adaClassify(dataArray,self.estimators_)+1)/2\n",
    "     \n",
    "    def stumpClassify(dataArray,dimen,threshVal,threshIneq):\n",
    "        retArray = np.ones((dataArray.shape[0],1))\n",
    "        if threshIneq == 'lt':\n",
    "            retArray[dataArray[:,dimen] <= threshVal] = -1.0\n",
    "        else:\n",
    "            retArray[dataArray[:,dimen] > threshVal] = -1.0\n",
    "        return retArray\n",
    "    \n",
    "    \n",
    "    def buildStump(dataArray,classLabels,D):\n",
    "        #D>errorRate->alpha->D\n",
    "        m,n=dataArray.shape\n",
    "        numSteps = 10.0;      \n",
    "        bestStump = {}  \n",
    "        bestClasEst = np.zeros((m,1)) ##\n",
    "        minError = np.inf \n",
    "\n",
    "        for i in range(n):\n",
    "            rangeMin = dataArray[:,i].min()\n",
    "            rangeMax = dataArray[:,i].max();\n",
    "            stepSize = (rangeMax-rangeMin)/numSteps\n",
    "\n",
    "            for j in range(-1,int(numSteps)+1):\n",
    "                for inequal in ['lt', 'gt']: \n",
    "                    threshVal = (rangeMin + float(j) * stepSize)\n",
    "                    predictedVals =AdaBoostClassifier.stumpClassify(dataArray,i,threshVal,inequal)\n",
    "                    errArr = np.ones((m,1))\n",
    "                    errArr[predictedVals == classLabels.reshape(-1,1)] = 0\n",
    "                    weightedError = D.T@errArr           \n",
    "                    if weightedError < minError:\n",
    "                        minError = weightedError\n",
    "                        bestClasEst = predictedVals.copy()\n",
    "                        bestStump['dim'] = i\n",
    "                        bestStump['thresh'] = threshVal\n",
    "                        bestStump['ineq'] = inequal\n",
    "        return bestStump,minError,bestClasEst\n",
    "        \n",
    "    def adaBoostTrainDS(dataArr,classLabels,numIt=500):\n",
    "        weakClassArr = []              #week classifier list\n",
    "        m,_= dataArr.shape\n",
    "        D = np.ones((m,1))/m         #initalize the predicted  value\n",
    "        aggClassEst = np.zeros((m,1))   #initalize the pedicted value\n",
    "        alphas=[]\n",
    "        estimator_errors_=[]\n",
    "        for i in range(numIt):\n",
    "            bestStump,error,classEst = AdaBoostClassifier.buildStump(dataArr,classLabels,D) #get the best split dim and value,predict list\n",
    "            alpha = float(0.5*np.log((1.0-error)/max(error,1e-16)))  #calculate alpha\n",
    "            alphas.append(alpha)\n",
    "            bestStump['alpha'] = alpha  \n",
    "            weakClassArr.append(bestStump)                \n",
    "            expon = np.multiply(-alpha*classLabels.reshape(-1,1),classEst)                              \n",
    "            D = np.multiply(D,np.exp(expon))/D.sum()                #update weight\n",
    "            aggClassEst += alpha*classEst           #update the prrdicted value of the loop\n",
    "            aggErrors = np.multiply(np.sign(aggClassEst) != classLabels.reshape(-1,1),np.ones((m,1))) #calculate the error rate\n",
    "            errorRate = aggErrors.sum()/m           #calculate the  error rate\n",
    "            estimator_errors_.append(errorRate)\n",
    "            if errorRate == 0.0: \n",
    "                break\n",
    "                print('The error rate has been reduced to 0, break the loop')\n",
    "        return weakClassArr,np.array(alphas),np.array(estimator_errors_)\n",
    "    \n",
    "    def adaClassify(datToClass,classifierArr):\n",
    "        m,_= datToClass.shape\n",
    "        aggClassEst = np.zeros((m,1))\n",
    "        for i in range(len(classifierArr)):\n",
    "            classEst = AdaBoostClassifier.stumpClassify(datToClass,classifierArr[i]['dim'],\\\n",
    "                                     classifierArr[i]['thresh'],\\\n",
    "                                     classifierArr[i]['ineq'])\n",
    "            aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        return np.sign(aggClassEst).flatten()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X,y=load_breast_cancer().data,load_breast_cancer().target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "model=AdaBoostClassifier(numIt=500).fit(X_train,y_train)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
