{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H: \n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "def selectJrand(i,m):\n",
    "    j=i #we want to select any J not equal to i\n",
    "    while (j==i):\n",
    "        j = int(np.random.uniform(0,m))\n",
    "    return j\n",
    "def kernelTrans(X, A, kTup): #calc the kernel or transform data to a higher dimensional space\n",
    "    m,n = np.shape(X)\n",
    "    K = np.mat(np.zeros((m,1)))\n",
    "    if kTup[0]=='linear': K = X * A.T   #linear kernel\n",
    "    elif kTup[0]=='rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = np.mat(X[j,:] - A)\n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        K = np.exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab\n",
    "    else: \n",
    "        raise NameError('Houston We Have a Problem That Kernel is not recognized')\n",
    "    return np.mat(K)\n",
    "\n",
    "class optStruct:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = np.shape(dataMatIn)[0]\n",
    "        self.alphas = np.mat(np.zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = np.mat(np.zeros((self.m,2))) #first column is valid flag\n",
    "        self.K = np.mat(np.zeros((self.m,self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n",
    "        \n",
    "def calcEk(oS, k):\n",
    "    fXk = float(np.multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJ(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = np.nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue #don't calc for i, waste of time\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEk(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerL(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: \n",
    "            #print \"L==H\"; \n",
    "            return 0\n",
    "        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel\n",
    "        if eta >= 0: \n",
    "            #print \"eta>=0\"; \n",
    "            return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): \n",
    "            #print \"j not moving enough\"; \n",
    "            return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter,kTup=('linear', 0)):    #full Platt SMO\n",
    "    oS = optStruct(np.mat(dataMatIn),np.mat(classLabels).transpose(),C,toler, kTup)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                #print \"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = np.nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                #print \"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        #print \"iteration number: %d\" % iter\n",
    "    return oS.b,oS.alphas \n",
    "def calcWs(alphas,dataArr,classLabels):\n",
    "    X = np.mat(dataArr); \n",
    "    labelMat = np.mat(classLabels).transpose()\n",
    "    m,n = np.shape(X)\n",
    "    w = np.zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += np.multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C=1,gamma=1,kernel='linear',max_iter=2000,tol=1e-3):\n",
    "        self.c=C\n",
    "        self.kernel=kernel\n",
    "        self.max_iter=max_iter\n",
    "        self.tol=tol\n",
    "        self.gamma=1\n",
    "        self.kTup=(self.kernel,self.gamma)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        y=2*y-1\n",
    "        self.y=y\n",
    "        self.b,self.alphas=smoP(X,y,C=self.c,toler=self.tol,maxIter=self.max_iter,kTup=self.kTup)\n",
    "        self.w=calcWs(self.alphas,X,y).flatten()\n",
    "        self.support_index_=np.where(self.alphas>0)[0]\n",
    "        self.n_support_=len(self.support_index_)\n",
    "        self.support_vectors_=X[self.support_index_]\n",
    "        self.support_labels_=self.y[self.support_index_]\n",
    "        self.b=float((1/y[self.support_index_]-X[self.support_index_]@self.w)[0])\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        m,n = X.shape\n",
    "        r=[]\n",
    "        for i in range(m):\n",
    "            K = kernelTrans(self.support_vectors_,X[i],self.kTup)\n",
    "            predict=(np.sign(np.sum(K.T.A*(np.multiply(self.support_labels_,self.alphas[self.support_index_].T.A))) + self.b)+1)/2\n",
    "            r.append(predict)\n",
    "        return np.array(r)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "X,y=load_breast_cancer().data,load_breast_cancer().target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "np.random.seed(88)\n",
    "\n",
    "my_lrsvm=SVM(C=1,kernel='linear').fit(X_train,y_train)\n",
    "accuracy_score(y_test,my_lrsvm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lrsvm.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.055606193278665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lrsvm.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,  78, 131, 217, 294], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lrsvm.support_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lrsvm.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.23519234e-05, 4.52117925e-05, 6.33717438e-06, 7.62368789e-06,\n",
       "        1.31384851e-05, 2.09566551e-05]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lrsvm.alphas[my_lrsvm.support_index_].T.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n",
      "0.74\n",
      "0.74\n",
      "0.92\n",
      "0.74\n",
      "0.48\n",
      "0.92\n",
      "0.89\n",
      "0.74\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "X,y=make_gaussian_quantiles(n_classes=2,n_samples=500,random_state=7)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "for i in np.linspace(0.1,1,10):\n",
    "    my_svm=SVM(C=1,kernel='rbf',gamma=i).fit(X_train,y_train)\n",
    "    print(accuracy_score(y_test,my_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm=SVM(C=1,kernel='linear',gamma=1).fit(X_train,y_train)\n",
    "accuracy_score(y_test,my_svm.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
