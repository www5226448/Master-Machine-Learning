{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y=make_classification(n_classes=2,n_features=6,n_samples=300)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def fit(self,X,y):\n",
    "        y=2*y-1\n",
    "        W_b=np.random.randn(X.shape[1]+1)\n",
    "        res=minimize(0.5*W_b[:-1].dot(W_b[:-1].T),\n",
    "                     x0=W_b,\n",
    "                    constraints=({'type':'ineq',\n",
    "                                  \"args\":(X,y),\n",
    "                                  'fun':lambda X,y,W_b: (y*(X.dot(W_b[:-1].T)+W_b[-1])-1)}))\n",
    "        \n",
    "        return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (7,) and (299,) not aligned: 7 (dim 0) != 299 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-839b7a5edb73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-4573f3e417c1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m                     constraints=({'type':'ineq',\n\u001b[1;32m      8\u001b[0m                                   \u001b[0;34m\"args\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                   'fun':lambda X,y,W_b: (y*(X.dot(W_b[:-1].T)+W_b[-1])-1)}))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slsqp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         return _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 495\u001b[0;31m                                constraints, callback=callback, **options)\n\u001b[0m\u001b[1;32m    496\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dogleg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         return _minimize_dogleg(fun, x0, args, jac, hess,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    312\u001b[0m               for c in cons['eq']]))\n\u001b[1;32m    313\u001b[0m     mieq = sum(map(len, [atleast_1d(c['fun'](x, *c['args']))\n\u001b[0;32m--> 314\u001b[0;31m                for c in cons['ineq']]))\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;31m# m = The total number of constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmieq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m               for c in cons['eq']]))\n\u001b[1;32m    313\u001b[0m     mieq = sum(map(len, [atleast_1d(c['fun'](x, *c['args']))\n\u001b[0;32m--> 314\u001b[0;31m                for c in cons['ineq']]))\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;31m# m = The total number of constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmieq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-4573f3e417c1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(X, y, W_b)\u001b[0m\n\u001b[1;32m      7\u001b[0m                     constraints=({'type':'ineq',\n\u001b[1;32m      8\u001b[0m                                   \u001b[0;34m\"args\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                   'fun':lambda X,y,W_b: (y*(X.dot(W_b[:-1].T)+W_b[-1])-1)}))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (7,) and (299,) not aligned: 7 (dim 0) != 299 (dim 0)"
     ]
    }
   ],
   "source": [
    "model=SVM()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(if L==H: print \"L==H\"; continue)? (<ipython-input-43-e3923246397d>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-e3923246397d>\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    if L==H: print \"L==H\"; continue\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(if L==H: print \"L==H\"; continue)?\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Nov 4, 2010\n",
    "Chapter 5 source file for Machine Learing in Action\n",
    "@author: Peter\n",
    "'''\n",
    "from numpy import *\n",
    "from time import sleep\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "def selectJrand(i,m):\n",
    "    j=i #we want to select any J not equal to i\n",
    "    while (j==i):\n",
    "        j = int(random.uniform(0,m))\n",
    "    return j\n",
    "\n",
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H: \n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    dataMatrix = mat(dataMatIn); labelMat = mat(classLabels).transpose()\n",
    "    b = 0; m,n = shape(dataMatrix)\n",
    "    alphas = mat(zeros((m,1)))\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b\n",
    "            Ei = fXi - float(labelMat[i])#if checks if an example violates KKT conditions\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                j = selectJrand(i,m)\n",
    "                fXj = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print \"L==H\"; continue\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if eta >= 0: print \"eta>=0\"; continue\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print \"j not moving enough\"; continue\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])#update i by the same amount as j\n",
    "                                                                        #the update is in the oppostie direction\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print \"iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "        if (alphaPairsChanged == 0): iter += 1\n",
    "        else: iter = 0\n",
    "        print \"iteration number: %d\" % iter\n",
    "    return b,alphas\n",
    "\n",
    "def kernelTrans(X, A, kTup): #calc the kernel or transform data to a higher dimensional space\n",
    "    m,n = shape(X)\n",
    "    K = mat(zeros((m,1)))\n",
    "    if kTup[0]=='lin': K = X * A.T   #linear kernel\n",
    "    elif kTup[0]=='rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j,:] - A\n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        K = exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab\n",
    "    else: raise NameError('Houston We Have a Problem -- \\\n",
    "    That Kernel is not recognized')\n",
    "    return K\n",
    "\n",
    "class optStruct:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m,2))) #first column is valid flag\n",
    "        self.K = mat(zeros((self.m,self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n",
    "        \n",
    "def calcEk(oS, k):\n",
    "    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJ(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue #don't calc for i, waste of time\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEk(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerL(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: print \"L==H\"; return 0\n",
    "        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel\n",
    "        if eta >= 0: print \"eta>=0\"; return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): print \"j not moving enough\"; return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter,kTup=('lin', 0)):    #full Platt SMO\n",
    "    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print \"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print \"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        print \"iteration number: %d\" % iter\n",
    "    return oS.b,oS.alphas\n",
    "\n",
    "def calcWs(alphas,dataArr,classLabels):\n",
    "    X = mat(dataArr); labelMat = mat(classLabels).transpose()\n",
    "    m,n = shape(X)\n",
    "    w = zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w\n",
    "\n",
    "def testRbf(k1=1.3):\n",
    "    dataArr,labelArr = loadDataSet('testSetRBF.txt')\n",
    "    b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', k1)) #C=200 important\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    svInd=nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] #get matrix of only support vectors\n",
    "    labelSV = labelMat[svInd];\n",
    "    print \"there are %d Support Vectors\" % shape(sVs)[0]\n",
    "    m,n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1\n",
    "    print (\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    dataArr,labelArr = loadDataSet('testSetRBF2.txt')\n",
    "    errorCount = 0\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    m,n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1    \n",
    "    print (\"the test error rate is: %f\" % (float(errorCount)/m) )   \n",
    "    \n",
    "def img2vector(filename):\n",
    "    returnVect = zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "def loadImages(dirName):\n",
    "    from os import listdir\n",
    "    hwLabels = []\n",
    "    trainingFileList = listdir(dirName)           #load the training set\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]     #take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        if classNumStr == 9: hwLabels.append(-1)\n",
    "        else: hwLabels.append(1)\n",
    "        trainingMat[i,:] = img2vector('%s/%s' % (dirName, fileNameStr))\n",
    "    return trainingMat, hwLabels    \n",
    "\n",
    "def testDigits(kTup=('rbf', 10)):\n",
    "    dataArr,labelArr = loadImages('trainingDigits')\n",
    "    b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, kTup)\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    svInd=nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] \n",
    "    labelSV = labelMat[svInd];\n",
    "    print \"there are %d Support Vectors\" % shape(sVs)[0]\n",
    "    m,n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1\n",
    "    print \"the training error rate is: %f\" % (float(errorCount)/m)\n",
    "    dataArr,labelArr = loadImages('testDigits')\n",
    "    errorCount = 0\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    m,n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1    \n",
    "    print(\"the test error rate is: %f\" % (float(errorCount)/m)) \n",
    "\n",
    "\n",
    "'''#######********************************\n",
    "Non-Kernel VErsions below\n",
    "'''#######********************************\n",
    "\n",
    "class optStructK:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m,2))) #first column is valid flag\n",
    "        \n",
    "def calcEkK(oS, k):\n",
    "    fXk = float(multiply(oS.alphas,oS.labelMat).T*(oS.X*oS.X[k,:].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJK(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue #don't calc for i, waste of time\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEkK(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerLK(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: print \"L==H\"; return 0\n",
    "        eta = 2.0 * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T\n",
    "        if eta >= 0: print \"eta>=0\"; return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): print \"j not moving enough\"; return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def smoPK(dataMatIn, classLabels, C, toler, maxIter):    #full Platt SMO\n",
    "    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print \"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print \"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        print \"iteration number: %d\" % iter\n",
    "    return oS.b,oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
