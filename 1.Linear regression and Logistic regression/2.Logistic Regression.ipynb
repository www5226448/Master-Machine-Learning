{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X,y=make_classification(n_classes=2,n_features=5,n_samples=300)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用sklearn求解Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.52148023  0.03638994 -0.18944455  0.38930781 -0.20435344]] [-0.16358819]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84        43\n",
      "          1       0.85      0.85      0.85        47\n",
      "\n",
      "avg / total       0.84      0.84      0.84        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "model=LogisticRegression(fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "pre=model.predict(X_test)\n",
    "print(model.coef_,model.intercept_)\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Scipy求解Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.81      0.84        43\n",
      "          1       0.84      0.89      0.87        47\n",
      "\n",
      "avg / total       0.86      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "def lost(w,X,y,c=0.1):\n",
    "    m,n=X.shape\n",
    "    j1=np.sum(y*np.log(expit(np.dot(X,w)))/-m)\n",
    "    j2=np.sum((1-y)*np.log(1-expit(np.dot(X,w)))/-m)\n",
    "    j3=np.sum(np.square(w))*(c/2*m)\n",
    "    return j1+j2+j3\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self,c=0.1):\n",
    "        self.c=c\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.m,self.n=X.shape\n",
    "        init_w=np.random.randn(self.n)\n",
    "        res=minimize(lost,init_w,args=(X,y))\n",
    "        self.res=res\n",
    "        self.coef_=self.res.x\n",
    "        \n",
    "    def predict(self,X):\n",
    "        prob=expit(np.dot(X,self.res.x.T)+np.sum(np.square(self.res.x))*(0.1/2*self.m))\n",
    "        pre=np.array([1 if i>0.5 else 0 for i in prob])\n",
    "        return pre\n",
    "    \n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "res=model.predict(X_test)\n",
    "print(classification_report(y_test,res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self,alpha=0.007,maxCycles=1800):\n",
    "        self.alpha=alpha\n",
    "        self.maxCycles=maxCycles\n",
    "    def fit(self,X,y):\n",
    "        X_=np.full((X.shape[0],1),fill_value=1)   \n",
    "        X=np.mat(np.concatenate([X,X_],axis=1))       \n",
    "        y = np.mat(y).transpose()\n",
    "        m,n = X.shape\n",
    "        weights = np.mat(np.random.randn(n,1))\n",
    "        for k in range(self.maxCycles):\n",
    "            h = expit(X*weights)  \n",
    "            error = h - y            \n",
    "            weights = weights - self.alpha * X.transpose()* error\n",
    "        self.coef_=np.array(weights).flatten()[:-1]\n",
    "        self.intercept_=weights[-1]\n",
    "        self.weights=weights\n",
    "    def predict(self,X):\n",
    "        X_=np.full((X.shape[0],1),fill_value=1)   \n",
    "        X=np.concatenate([X,X_],axis=1)\n",
    "        y_value=np.array(expit(np.mat(X)*self.weights)).flatten()\n",
    "        y_pre=np.array([1 if i>0.5 else 0 for i in y_value])\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84        43\n",
      "          1       0.85      0.85      0.85        47\n",
      "\n",
      "avg / total       0.84      0.84      0.84        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=MyLogisticRegression(alpha=0.004,maxCycles=1000)\n",
    "model.fit(X_train,y_train)\n",
    "y_pre=model.predict(X_test)\n",
    "print(classification_report(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用模型预测收入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "data=pd.read_csv('DecisionTree.csv')\n",
    "X=data[['workclass', 'education', 'marital-status', 'occupation',\n",
    "       'relationship', 'race', 'gender', 'native-country']]\n",
    "y=[0 if i=='<=50K' else 1 for i in data['income'].tolist()]\n",
    "X=pd.get_dummies(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "model=MyLogisticRegression()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pre=model.predict(X_test.values)\n",
    "accuracy_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self,alpha=0.007,maxCycles=1800):\n",
    "        self.alpha=alpha\n",
    "        self.maxCycles=maxCycles\n",
    "    def fit(self,X, y, numIter=150):\n",
    "        X_=np.full((X.shape[0],1),fill_value=1)   \n",
    "        X=(np.concatenate([X,X_],axis=1)) \n",
    "        m,n = X.shape\n",
    "        weights = np.ones(n)   \n",
    "        for j in range(numIter):\n",
    "            dataIndex = list(range(m))\n",
    "            for i in range(m):\n",
    "                alpha = 4/(1.0+j+i)+0.0001   \n",
    "                randIndex = int(np.random.uniform(0,len(dataIndex))) \n",
    "                h = expit(sum(X[randIndex]*weights))\n",
    "                error = h-y[randIndex] \n",
    "                weights = weights - alpha * error * X[randIndex]\n",
    "                del(dataIndex[randIndex])\n",
    "        self.coef_=weights[:-1]\n",
    "        self.intercept=weights[-1]\n",
    "        self.weights=np.mat(weights).transpose()\n",
    "        return weights\n",
    "    def predict(self,X):\n",
    "        X_=np.full((X.shape[0],1),fill_value=1)   \n",
    "        X=(np.concatenate([X,X_],axis=1)) \n",
    "        y_value=np.array(expit(np.mat(X)*self.weights)).flatten()\n",
    "        y_pre=np.array([1 if i>0.5 else 0 for i in y_value])\n",
    "        return y_pre\n",
    "    def predict_prob(self,X):\n",
    "        X_=np.full((X.shape[0],1),fill_value=1)   \n",
    "        X=(np.concatenate([X,X_],axis=1)) \n",
    "        y_value=np.array(expit(np.mat(X)*self.weights)).flatten()\n",
    "        y_value=np.array(expit(np.mat(X)*self.weights)).flatten()\n",
    "        return y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyLogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "pre=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pre))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
